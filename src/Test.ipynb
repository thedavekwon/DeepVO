{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs=[\"01\"]\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cur, model, optimizer = load_model(device, \"radam\", 0.0001, \"../weights/205.weights\")\n",
    "\n",
    "train_dl = DataLoader(KittiPredefinedDataset(), batch_size=10, shuffle=True, num_workers=8)\n",
    "# vali_dl  = DataLoader(KittiPredefinedValidationDataset(), batch_size=24, shuffle=False, num_workers=12)\n",
    "test_dl = DataLoader(KittiPredefinedDataset(seqs=[\"01\"]), batch_size=10, shuffle=False, num_workers=8)\n",
    "\n",
    "weight_folder = \"weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n",
      "200th loss: 0.00017183402978844243\n",
      "400th loss: 0.0001751417020932422\n",
      "600th loss: 0.0001820193064486375\n",
      "800th loss: 0.00017102360790886452\n",
      "1000th loss: 0.00018138633990020026\n",
      "1200th loss: 0.00017407234852726106\n",
      "1400th loss: 0.00017132530145318016\n",
      "Train Epoch 206th loss: 0.00017514170307284712\n",
      "207\n",
      "200th loss: 0.0001745983460568823\n",
      "400th loss: 0.00018372205333434975\n",
      "600th loss: 0.00018124676196748624\n",
      "800th loss: 0.0001829916236238205\n",
      "1000th loss: 0.00017057663939340273\n",
      "1200th loss: 0.00016171490633496433\n",
      "1400th loss: 0.00018242502483190037\n",
      "Train Epoch 207th loss: 0.00017700696365409077\n",
      "208\n",
      "200th loss: 0.000179613233449345\n",
      "400th loss: 0.00017102422829339047\n",
      "600th loss: 0.00018202054368885\n",
      "800th loss: 0.00017677117506536888\n",
      "1000th loss: 0.00017898236266773891\n",
      "1200th loss: 0.00017112028603150976\n",
      "1400th loss: 0.00017522125592222437\n",
      "Train Epoch 208th loss: 0.00017731181152750702\n",
      "209\n",
      "200th loss: 0.00017952121768757934\n",
      "400th loss: 0.00017336592954961816\n",
      "600th loss: 0.00018181617386289872\n",
      "800th loss: 0.00018219043151475488\n",
      "1000th loss: 0.00017886158686451382\n",
      "1200th loss: 0.00017542050110932905\n",
      "1400th loss: 0.0001717680986621417\n",
      "Train Epoch 209th loss: 0.0001783117539380377\n",
      "210\n",
      "200th loss: 0.00017738312963047064\n",
      "400th loss: 0.00017324630454822908\n",
      "600th loss: 0.00016821586334117455\n",
      "800th loss: 0.00016850626718223794\n",
      "1000th loss: 0.0001745569705235539\n",
      "1200th loss: 0.00018751264582533622\n",
      "1400th loss: 0.0001754735924259876\n",
      "Train Epoch 210th loss: 0.00017523720987808067\n",
      "211\n",
      "200th loss: 0.00017161376374133397\n",
      "400th loss: 0.00017455948460337823\n",
      "600th loss: 0.00017114865786425071\n",
      "800th loss: 0.0001808604510006262\n",
      "1000th loss: 0.0001778644066871493\n",
      "1200th loss: 0.00017715549292915967\n",
      "1400th loss: 0.00017585155097549432\n",
      "Train Epoch 211th loss: 0.0001755910796336723\n",
      "212\n",
      "200th loss: 0.00017270298885705416\n",
      "400th loss: 0.00016993970923067536\n",
      "600th loss: 0.00017840724685811438\n",
      "800th loss: 0.0001639205812352884\n",
      "1000th loss: 0.00018684166938328416\n",
      "1200th loss: 0.000177988733012171\n",
      "1400th loss: 0.00018234076855151216\n",
      "Train Epoch 212th loss: 0.0001763567596633185\n",
      "213\n",
      "200th loss: 0.00017820979988755425\n",
      "400th loss: 0.0001839174277483835\n",
      "600th loss: 0.00017862916840385878\n",
      "800th loss: 0.00017722159287586692\n",
      "1000th loss: 0.00017394232112565077\n",
      "1200th loss: 0.00017755200824467465\n",
      "1400th loss: 0.00017675441013125236\n",
      "Train Epoch 213th loss: 0.0001773189192525193\n",
      "214\n",
      "200th loss: 0.00017476383149187314\n",
      "400th loss: 0.00017559179936142753\n",
      "600th loss: 0.0001776470437835087\n",
      "800th loss: 0.00017818106156482826\n",
      "1000th loss: 0.0001725699135567993\n",
      "1200th loss: 0.00017026889931003096\n",
      "1400th loss: 0.00017047237764927558\n",
      "Train Epoch 214th loss: 0.00017399822595019873\n",
      "215\n",
      "200th loss: 0.00018168459293519846\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 200\n",
    "for e in range(cur+1, cur+EPOCH+1):\n",
    "    print(e)\n",
    "    train(model, train_dl, optimizer, device, e, weight_folder)\n",
    "    gt, pred = test(model, test_dl, device)\n",
    "    draw_route(gt, pred, str(e), weight_folder)\n",
    "    cur = cur + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}